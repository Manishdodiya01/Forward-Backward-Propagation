{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b65e46c4-76d4-474f-965c-23c07bbfbe38",
   "metadata": {},
   "source": [
    "# Q1. What is the purpose of forward propagation in a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9df87ec-8476-4eb3-920f-fc83311a49ff",
   "metadata": {},
   "source": [
    "Forward propagation is a fundamental step in the training and operation of a neural network. Its primary purpose is to compute the output of the neural network for a given input. Here's a breakdown of the key steps involved in forward propagation:\n",
    "\n",
    "1. **Input Layer:**\n",
    "   - The process begins with the input layer, where the features of the input data are fed into the neural network.\n",
    "\n",
    "2. **Weighted Sum and Activation:**\n",
    "   - Each neuron (or node) in the subsequent layers performs a weighted sum of its inputs, where each input is multiplied by its corresponding weight.\n",
    "   - The weighted sum is then passed through an activation function, which introduces non-linearity to the model. Common activation functions include sigmoid, tanh, and ReLU (Rectified Linear Unit).\n",
    "\n",
    "3. **Output Layer:**\n",
    "   - The process continues through the hidden layers until the final layer, which is the output layer. The output layer produces the final result of the neural network for the given input.\n",
    "\n",
    "4. **Loss Calculation:**\n",
    "   - The output is then compared to the actual target values, and the difference (loss) is calculated. The choice of the loss function depends on the type of task (e.g., regression, classification) and the specific requirements.\n",
    "\n",
    "5. **Backpropagation Preparation:**\n",
    "   - The computed output and the actual target values are used to calculate the gradient of the loss with respect to the weights of the network. This gradient information is crucial for adjusting the weights during the training process.\n",
    "\n",
    "Forward propagation is essentially the process of passing input data through the neural network to obtain predictions, and it sets the stage for the subsequent backward propagation (backpropagation) process, which is used to update the weights of the network based on the computed gradients. This iterative process of forward and backward propagation is fundamental to training a neural network to learn from data and make accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3a010-62c4-4b3b-bab6-ec2e5157b6ab",
   "metadata": {},
   "source": [
    "# Q2. How is forward propagation implemented mathematically in a single-layer feedforward neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb85d85-104d-48fd-b1c6-afe92222b639",
   "metadata": {},
   "source": [
    "In a single-layer feedforward neural network, also known as a perceptron or a single-layer perceptron (SLP), there is an input layer and an output layer, but no hidden layers. The mathematical implementation of forward propagation in such a network is relatively straightforward. Let's denote the following variables:\n",
    "\n",
    "- \\(X\\): Input vector (features)\n",
    "- \\(W\\): Weight matrix\n",
    "- \\(b\\): Bias vector\n",
    "- \\(Z\\): Weighted sum of inputs\n",
    "- \\(A\\): Output after applying the activation function\n",
    "\n",
    "The steps for forward propagation in a single-layer feedforward neural network are as follows:\n",
    "\n",
    "1. **Compute the Weighted Sum (\\(Z\\)):**\n",
    "   \\[ Z = X \\cdot W + b \\]\n",
    "\n",
    "   Here, \\(X\\) is a row vector representing the input features, \\(W\\) is the weight matrix, \\(b\\) is the bias vector, and \\(\\cdot\\) denotes matrix multiplication.\n",
    "\n",
    "2. **Apply Activation Function (\\(A\\)):**\n",
    "   \\[ A = \\text{Activation}(Z) \\]\n",
    "\n",
    "   The activation function introduces non-linearity into the model. Common activation functions include the sigmoid function (\\(\\sigma(Z)\\)), hyperbolic tangent (\\(\\tanh(Z)\\)), or the rectified linear unit (ReLU) function (\\(\\max(0, Z)\\)).\n",
    "\n",
    "3. **Output (\\(A\\)):**\n",
    "   The output \\(A\\) is the result of the forward propagation and is used for further steps such as calculating the loss and updating the weights during training.\n",
    "\n",
    "Putting it all together, the forward propagation can be summarized mathematically as follows:\n",
    "\n",
    "\\[ Z = X \\cdot W + b \\]\n",
    "\n",
    "\\[ A = \\text{Activation}(Z) \\]\n",
    "\n",
    "For example, if the sigmoid activation function is used, the forward propagation equations become:\n",
    "\n",
    "\\[ Z = X \\cdot W + b \\]\n",
    "\n",
    "\\[ A = \\sigma(Z) \\]\n",
    "\n",
    "In the training phase, the output \\(A\\) is compared to the actual target values, and the model is updated using backpropagation to minimize the difference between the predicted and actual outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00e62d-4e0f-40c7-9619-185c65ca720c",
   "metadata": {},
   "source": [
    "# Q3. How are activation functions used during forward propagation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa15d343-3e55-46e3-8b69-64e39b1a9cf2",
   "metadata": {},
   "source": [
    "Activation functions are a crucial component of neural networks, and they are applied during forward propagation to introduce non-linearity to the model. The role of activation functions is to determine the output of a neuron and decide whether it should be activated (fired) or not, based on the weighted sum of inputs. Without activation functions, the neural network would essentially be a linear model, as the composition of linear functions remains linear.\n",
    "\n",
    "Here are some common activation functions and how they are used during forward propagation:\n",
    "\n",
    "1. **Sigmoid Activation Function (\\(\\sigma\\)):**\n",
    "   \\[ \\sigma(z) = \\frac{1}{1 + e^{-z}} \\]\n",
    "   - Maps the weighted sum \\(z\\) to values between 0 and 1.\n",
    "   - Used in the output layer of binary classification problems, where the goal is to produce a probability.\n",
    "\n",
    "2. **Hyperbolic Tangent Activation Function (\\(\\tanh\\)):**\n",
    "   \\[ \\tanh(z) = \\frac{e^{z} - e^{-z}}{e^{z} + e^{-z}} \\]\n",
    "   - Similar to the sigmoid but maps the weighted sum \\(z\\) to values between -1 and 1.\n",
    "   - Often used in hidden layers of neural networks.\n",
    "\n",
    "3. **Rectified Linear Unit (ReLU):**\n",
    "   \\[ \\text{ReLU}(z) = \\max(0, z) \\]\n",
    "   - Outputs the input if it is positive; otherwise, it outputs zero.\n",
    "   - Addresses the vanishing gradient problem and is computationally efficient.\n",
    "   - Commonly used in hidden layers.\n",
    "\n",
    "4. **Leaky ReLU:**\n",
    "   \\[ \\text{Leaky ReLU}(z) = \\max(\\alpha z, z) \\]\n",
    "   - Similar to ReLU but allows a small negative slope (\\(\\alpha\\)) for negative input values.\n",
    "   - Aims to address the \"dying ReLU\" problem where neurons can become inactive during training.\n",
    "\n",
    "5. **Softmax Activation Function:**\n",
    "   \\[ \\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}} \\]\n",
    "   - Used in the output layer for multi-class classification problems.\n",
    "   - Converts the raw scores (logits) into probability distributions over multiple classes.\n",
    "\n",
    "During forward propagation, the activation function is applied element-wise to the weighted sum of inputs for each neuron in the network. The resulting output is then passed to the next layer or used as the final output of the network, depending on whether it's an intermediate or output layer. The choice of activation function depends on the specific task, and experimentation is often conducted to determine the most effective activation function for a given neural network architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c940a99-7574-41ef-b9ff-f4bd4fc0760d",
   "metadata": {},
   "source": [
    "# Q4. What is the role of weights and biases in forward propagation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d09c247-7b92-41b1-9c79-f0e6192f7477",
   "metadata": {},
   "source": [
    "In the context of neural networks, weights and biases play a crucial role in forward propagation. Forward propagation is the process of passing input data through the network to compute the predicted output. The weights and biases are learnable parameters that are adjusted during the training process to make the network produce accurate predictions.\n",
    "\n",
    "1. **Weights:**\n",
    "   - Weights are parameters associated with the connections between neurons in adjacent layers of the neural network.\n",
    "   - Each connection between neurons has a weight, which determines the strength of the connection. The weights are initially assigned random values and are updated during the training process.\n",
    "   - In the forward propagation step, the weighted sum of the inputs to a neuron is calculated by multiplying each input by its corresponding weight and summing up these products. Mathematically, for a neuron in layer \\(l\\), the weighted sum (\\(z^{[l]}\\)) is computed as:\n",
    "     \\[ z^{[l]} = W^{[l]} \\cdot a^{[l-1]} + b^{[l]} \\]\n",
    "     where \\(W^{[l]}\\) is the weight matrix, \\(a^{[l-1]}\\) is the output from the previous layer, and \\(b^{[l]}\\) is the bias.\n",
    "\n",
    "2. **Biases:**\n",
    "   - Biases are parameters associated with each neuron in a layer, and they provide the model with flexibility by allowing neurons to activate even when the input is zero.\n",
    "   - In the forward propagation step, the bias term (\\(b^{[l]}\\)) is added to the weighted sum (\\(z^{[l]}\\)) before applying the activation function. This helps the model capture patterns and relationships that might not be present in the raw input data.\n",
    "   - The bias term allows the activation function to shift the output up or down, influencing whether a neuron should be activated.\n",
    "   \n",
    "In summary, weights and biases are critical parameters that the neural network learns during the training process. They determine how input features are combined and transformed as they pass through the layers of the network, ultimately influencing the model's ability to make accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4283040f-a3d1-4b29-bb37-ec381a972882",
   "metadata": {},
   "source": [
    "# Q5. What is the purpose of applying a softmax function in the output layer during forward propagation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bcda3e-ab01-4d6f-a892-d73051b03ed3",
   "metadata": {},
   "source": [
    "The softmax function is commonly used in the output layer of a neural network, especially in multi-class classification problems. Its primary purpose is to convert the raw scores or logits produced by the network into a probability distribution over multiple classes. The softmax function normalizes the output values, making them represent probabilities that sum to 1. This is crucial for interpreting the network's output as class probabilities.\n",
    "\n",
    "The softmax function is defined as follows for a vector \\( z = (z_1, z_2, ..., z_K) \\):\n",
    "\n",
    "\\[ \\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}} \\]\n",
    "\n",
    "Here's why the softmax function is used:\n",
    "\n",
    "1. **Probability Interpretation:**\n",
    "   - The softmax function converts the raw scores (logits) into a probability distribution. Each element of the output vector represents the probability of the corresponding class.\n",
    "\n",
    "2. **Sum to 1:**\n",
    "   - The probabilities produced by the softmax function always sum to 1. This property is essential for interpreting the output as a valid probability distribution.\n",
    "\n",
    "3. **Relative Magnitudes:**\n",
    "   - The softmax operation maintains the relative magnitudes of the logits. Even if one logit is much larger than the others, the resulting probability distribution will still reflect the relationships between the classes.\n",
    "\n",
    "4. **Differentiability:**\n",
    "   - The softmax function is differentiable, making it suitable for use in gradient-based optimization algorithms such as backpropagation during training.\n",
    "\n",
    "In the context of a neural network's forward propagation, the softmax function is typically applied to the output layer after the final weighted sum and activation function (if any). If \\(z\\) represents the logits produced by the network for each class, then the softmax operation is applied to obtain the final probabilities:\n",
    "\n",
    "\\[ \\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}} \\]\n",
    "\n",
    "where \\(K\\) is the number of classes.\n",
    "\n",
    "In summary, the softmax function ensures that the output of the neural network in a multi-class classification task is not only a set of raw scores but a meaningful probability distribution that can be used to make predictions and assess the model's confidence in those predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e5b89-44d5-4a37-8b57-5beaaf081e7f",
   "metadata": {},
   "source": [
    "# Q6. What is the purpose of backward propagation in a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f034f42-40b1-444e-b1e6-530aad3a0c0c",
   "metadata": {},
   "source": [
    "Backward propagation, also known as backpropagation, is a crucial step in training a neural network. The purpose of backward propagation is to adjust the weights and biases of the network based on the computed error, thereby minimizing the difference between the predicted output and the actual target values. It is an optimization algorithm used in conjunction with a loss function to update the model's parameters.\n",
    "\n",
    "Here's a step-by-step overview of the purpose of backward propagation:\n",
    "\n",
    "1. **Compute Loss:**\n",
    "   - During forward propagation, the model makes predictions on the input data, and the output is compared to the actual target values using a loss function. The loss function measures the error or the difference between the predicted output and the true target values.\n",
    "\n",
    "2. **Backward Pass:**\n",
    "   - The backward pass involves calculating the gradient of the loss with respect to the model parameters (weights and biases). The gradient represents the sensitivity of the loss to changes in the parameters.\n",
    "   - The chain rule from calculus is applied to compute the gradients layer by layer, starting from the output layer and moving backward through the network.\n",
    "\n",
    "3. **Update Parameters:**\n",
    "   - The computed gradients are used to update the model parameters (weights and biases) in the direction that reduces the loss. This is typically done using an optimization algorithm, such as gradient descent or one of its variants.\n",
    "   - The learning rate, a hyperparameter, controls the size of the updates and is crucial for the stability and convergence of the training process.\n",
    "\n",
    "4. **Iterative Process:**\n",
    "   - Steps 1-3 are repeated iteratively for multiple batches of training data or epochs until the model's performance converges to an acceptable level. Each iteration improves the model's ability to make accurate predictions on the training data.\n",
    "\n",
    "By iteratively adjusting the weights and biases based on the gradients of the loss function, backward propagation enables the neural network to learn from the training data and improve its performance over time. It is a key component of the training process and is essential for the model to generalize well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eee0cb-5bea-41ae-89a2-4e639c0b63cf",
   "metadata": {},
   "source": [
    "# Q7. How is backward propagation mathematically calculated in a single-layer feedforward neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76e7ab5-e9f2-4c4e-be5c-67905c5241a4",
   "metadata": {},
   "source": [
    "Backward propagation, also known as backpropagation, is a crucial step in training a neural network. It involves computing the gradients of the loss with respect to the parameters (weights and biases) of the network, which are then used to update the parameters during the optimization process. In a single-layer feedforward neural network (perceptron), the mathematical calculations for backpropagation are relatively simple compared to deeper architectures with hidden layers. Let's go through the steps:\n",
    "\n",
    "1. **Loss Function:**\n",
    "   - Let \\(L\\) be the loss function that measures the difference between the predicted output \\(A\\) and the actual target values.\n",
    "\n",
    "2. **Gradient of the Loss with Respect to the Output (\\(\\frac{\\partial L}{\\partial A}\\)):**\n",
    "   - Calculate the gradient of the loss with respect to the output of the network.\n",
    "   \\[ \\frac{\\partial L}{\\partial A} = \\text{Gradient of the Loss} \\]\n",
    "\n",
    "3. **Gradient of the Output with Respect to the Weighted Sum (\\(\\frac{\\partial A}{\\partial Z}\\)):**\n",
    "   - Depending on the activation function used, compute the gradient of the output with respect to the weighted sum.\n",
    "   - For example, if using the sigmoid activation function:\n",
    "     \\[ \\frac{\\partial A}{\\partial Z} = A \\cdot (1 - A) \\]\n",
    "\n",
    "4. **Gradient of the Loss with Respect to the Weighted Sum (\\(\\frac{\\partial L}{\\partial Z}\\)):**\n",
    "   - Apply the chain rule to compute the gradient of the loss with respect to the weighted sum.\n",
    "   \\[ \\frac{\\partial L}{\\partial Z} = \\frac{\\partial L}{\\partial A} \\cdot \\frac{\\partial A}{\\partial Z} \\]\n",
    "\n",
    "5. **Gradient of the Loss with Respect to the Weights (\\(\\frac{\\partial L}{\\partial W}\\)) and Bias (\\(\\frac{\\partial L}{\\partial b}\\)):**\n",
    "   - Compute the gradients of the loss with respect to the weights and bias using the gradients calculated above.\n",
    "   \\[ \\frac{\\partial L}{\\partial W} = X^T \\cdot \\frac{\\partial L}{\\partial Z} \\]\n",
    "   \\[ \\frac{\\partial L}{\\partial b} = \\sum \\frac{\\partial L}{\\partial Z} \\]\n",
    "\n",
    "6. **Update Weights and Bias:**\n",
    "   - Use the gradients obtained to update the weights and bias using an optimization algorithm (e.g., gradient descent).\n",
    "   \\[ W = W - \\alpha \\cdot \\frac{\\partial L}{\\partial W} \\]\n",
    "   \\[ b = b - \\alpha \\cdot \\frac{\\partial L}{\\partial b} \\]\n",
    "\n",
    "Here, \\(\\alpha\\) represents the learning rate, which determines the size of the steps taken during optimization.\n",
    "\n",
    "These steps constitute the basic backpropagation process for a single-layer feedforward neural network. The gradients are calculated backward through the network, starting from the output layer and propagating towards the input layer. This process is repeated iteratively during the training phase to gradually improve the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e9d1c8-e587-4514-802e-b5f36b9b2650",
   "metadata": {},
   "source": [
    "# Q8. Can you explain the concept of the chain rule and its application in backward propagation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39bf7f-7ea1-4609-8ade-a7f003a51093",
   "metadata": {},
   "source": [
    "Certainly! The chain rule is a fundamental concept in calculus that is used to find the derivative of a composite function. In the context of neural networks and backward propagation, the chain rule is applied to compute the gradients of the loss with respect to the parameters (weights and biases) of the network.\n",
    "\n",
    "Let's consider a simple neural network with a single hidden layer. The output of the network is denoted as \\( \\hat{y} \\), the true target values are \\( y \\), and the loss function is denoted as \\( J \\). The weights and biases are represented by \\( W \\) and \\( b \\).\n",
    "\n",
    "The forward propagation step for a single neuron in the network can be expressed as:\n",
    "\n",
    "\\[ z = W \\cdot x + b \\]\n",
    "\\[ a = \\sigma(z) \\]\n",
    "\\[ \\hat{y} = a \\]\n",
    "\n",
    "Here, \\( x \\) is the input, \\( z \\) is the weighted sum of inputs, \\( \\sigma \\) is the activation function, \\( a \\) is the output after activation, and \\( \\hat{y} \\) is the predicted output.\n",
    "\n",
    "The chain rule comes into play when calculating the gradients during backward propagation. The chain rule states that if you have a composite function \\( F(x) = f(g(x)) \\), then the derivative of \\( F \\) with respect to \\( x \\) is given by:\n",
    "\n",
    "\\[ \\frac{dF}{dx} = \\frac{df}{dg} \\cdot \\frac{dg}{dx} \\]\n",
    "\n",
    "Now, applying the chain rule to the neural network example:\n",
    "\n",
    "1. **Output Layer:**\n",
    "   - The derivative of the loss with respect to the predicted output \\( \\frac{dJ}{d\\hat{y}} \\) is computed.\n",
    "   - Then, the chain rule is applied to find \\( \\frac{dJ}{da} \\) and \\( \\frac{da}{dz} \\).\n",
    "\n",
    "2. **Hidden Layer:**\n",
    "   - The chain rule is applied again to find \\( \\frac{dz}{dW} \\), \\( \\frac{dz}{db} \\), \\( \\frac{dz}{dx} \\), where \\( x \\) is the input to the layer.\n",
    "\n",
    "3. **Parameter Update:**\n",
    "   - The computed derivatives are used to update the weights and biases in the direction that minimizes the loss.\n",
    "\n",
    "This process is repeated for each layer during backward propagation, allowing the network to learn from the training data by adjusting its parameters. The chain rule ensures that the gradients are propagated backward through the network correctly, capturing the influence of each parameter on the overall loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8861c0d-b57d-4c46-bc87-63ecff6e6e3f",
   "metadata": {},
   "source": [
    "# Q9. What are some common challenges or issues that can occur during backward propagation, and how can they be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cb15a8-4453-4405-b8f5-7bf4e375e204",
   "metadata": {},
   "source": [
    "During backward propagation (backpropagation), several challenges or issues may arise, impacting the training process and the performance of a neural network. Here are some common challenges and potential solutions:\n",
    "\n",
    "1. **Vanishing Gradients:**\n",
    "   - **Issue:** In deep networks, gradients may become very small as they are backpropagated through many layers, leading to slow or stalled learning in early layers.\n",
    "   - **Solution:** Use activation functions that mitigate vanishing gradients, such as ReLU or variants like Leaky ReLU. Batch normalization can also help stabilize gradients.\n",
    "\n",
    "2. **Exploding Gradients:**\n",
    "   - **Issue:** Gradients can become extremely large, causing weight updates to be too drastic and leading to convergence issues.\n",
    "   - **Solution:** Implement gradient clipping, where gradients exceeding a certain threshold are scaled down. This helps prevent exploding gradients without compromising the network's ability to learn.\n",
    "\n",
    "3. **Choice of Activation Functions:**\n",
    "   - **Issue:** The choice of activation functions can impact the network's ability to capture complex relationships in the data.\n",
    "   - **Solution:** Experiment with different activation functions based on the specific characteristics of the problem. ReLU is a common choice for hidden layers, but tasks such as binary classification might benefit from sigmoid in the output layer.\n",
    "\n",
    "4. **Learning Rate Selection:**\n",
    "   - **Issue:** An inappropriate learning rate can lead to slow convergence, overshooting, or divergence.\n",
    "   - **Solution:** Tune the learning rate through experimentation. Techniques like learning rate schedules or adaptive learning rate methods (e.g., Adam, RMSProp) can be employed to dynamically adjust the learning rate during training.\n",
    "\n",
    "5. **Overfitting:**\n",
    "   - **Issue:** The model may become too specialized to the training data and perform poorly on new, unseen data.\n",
    "   - **Solution:** Implement regularization techniques such as dropout, L1 or L2 regularization, or use techniques like early stopping. These methods help prevent the model from memorizing noise in the training data.\n",
    "\n",
    "6. **Data Quality and Quantity:**\n",
    "   - **Issue:** Insufficient or noisy training data can lead to poor generalization.\n",
    "   - **Solution:** Ensure a diverse and representative dataset. Augment the data if possible and use techniques like transfer learning if you have access to pre-trained models on similar tasks.\n",
    "\n",
    "7. **Architecture Complexity:**\n",
    "   - **Issue:** Very complex architectures may be prone to overfitting, slow training, and increased computational requirements.\n",
    "   - **Solution:** Consider the complexity of the problem and experiment with simpler architectures. Model complexity should be aligned with the complexity of the task.\n",
    "\n",
    "8. **Initialization of Weights:**\n",
    "   - **Issue:** Poor initialization of weights can lead to difficulties in convergence.\n",
    "   - **Solution:** Use initialization techniques such as Xavier/Glorot initialization or He initialization, which help balance the scale of weights in the network.\n",
    "\n",
    "9. **Batch Size Selection:**\n",
    "   - **Issue:** The choice of batch size can affect the stability of training and convergence.\n",
    "   - **Solution:** Experiment with different batch sizes. Smaller batch sizes may introduce more noise but can lead to faster convergence, while larger batch sizes provide a more stable estimate of the gradient.\n",
    "\n",
    "Addressing these challenges often involves a combination of proper architecture design, hyperparameter tuning, and regularization techniques. It's crucial to monitor the training process, validate the model on a separate dataset, and make adjustments as needed to achieve optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9325c0-7b9e-4688-b34e-401eff8c8047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
